---
title: "assignment_2"
author: "Tytgat"
date: "2 novembre 2018"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
source("functions_2.R")
install.packages("styler")
```
```{r}
`%>%` <- magrittr::`%>%`
```

## Exercice 1

#Permutation tests
```{r}
iris_subset_1 <- iris[c(89:94, 108:112), ]
iris_subset_2 <- iris[88:114, ]

permuted_1 <- permutation_twogroups(
  iris_subset_1,
  "Sepal.Width",
  "Species",
  "versicolor",
  "virginica",
  difference_in_medians
)

permuted_2 <- permutation_twogroups(
  iris_subset_2,
  "Sepal.Width",
  "Species",
  "versicolor",
  "virginica",
  difference_in_medians
)
```

#Sous-groupes et histogrammes

```{r}
ptest_1 <- tibble::as_tibble(permuted_1["permuted"])
ptest_2 <- tibble::as_tibble(permuted_2["permuted"])

observed_test_1 <- permuted_1["observed"]
observed_test_2 <- permuted_2["observed"]

low_bind <- min(ptest_1, ptest_2)
high_bind <- max(ptest_1, ptest_2)

p_1 <- ggplot2::ggplot(ptest_1, ggplot2::aes(x = permuted)) +
  ggplot2::geom_histogram(fill = "#FFD86D", colour = "black")
p_1 <- p_1 + ggplot2::geom_vline(xintercept = unlist(observed_test_1))
p_1 <- p_1 + ggplot2::xlim(low_bind, high_bind)
print(p_1)

p_2 <- ggplot2::ggplot(ptest_2, ggplot2::aes(x = permuted)) +
  ggplot2::geom_histogram(fill = "#FFD86D", colour = "black")
p_2 <- p_2 + ggplot2::geom_vline(xintercept = unlist(observed_test_2))
p_2 <- p_2 + ggplot2::xlim(low_bind, high_bind)
print(p_2)
```

####Interprétation

Les deux histogrammes présentent des formes très différentes. Le premier jeu de données qui y est représenté, est vide au centre et plus présent sur ses extrêmes. A l'inverse le second suit une représentation pour régulière, plus proche d'une loi normale de distribution, avec une forte présence au centre, qui diminue et allant vers les extremums (même si on a toujours des colonnes vides, juste en dessous de 0). 

La valeur observée des deux sets se situe à un endroit similaire, vers -0,25, mais est plut petite pour le premier groupe (vers 500). 

Ces deux observations sont liées au fait que les deux jeux de données ont été crée avec des sous-groupes de données de tailles différentes (6 pour l'un, 13 pour l'autre - soit du simple au double). Cela montre bien que la façon de regrouper des données, qui peut être très arbitraire, peut grandement affecter la façon dont on les analyse.

####P-value

```{r}
t.test(as.data.frame(ptest_1))
t.test(as.data.frame(ptest_2))
```

##Exercice 2

```{r}
devtools::install_github("ewan/stats_course", subdir = "data/stress_shift")
```

####Task A

```{r}
stress_shift_3dict <- dplyr::filter(stressshift::stress_shift_unamb, Dict == "W1802" | Dict == "J1917" | Dict == "C1687")
print(nrow(stress_shift_3dict))
```

####Task B

```{r}
stress_shift_3dict_using_pipe <- stressshift::stress_shift_unamb %>% dplyr::filter(Dict == "W1802" | Dict == "J1917" | Dict == "C1687")
print(identical(stress_shift_3dict, stress_shift_3dict_using_pipe))
```

####Task C

```{r}
stress_shift_3dict_nouns <- dplyr::filter(stress_shift_3dict, Category == "Noun")
stress_shift_3dict_verbs <- dplyr::filter(stress_shift_3dict, Category == "Verb")

stress_shift_3dict_using_bind <- dplyr::bind_rows(stress_shift_3dict_nouns, stress_shift_3dict_verbs)
stress_shift_3dict_using_reversed <- dplyr::bind_rows(stress_shift_3dict_verbs, stress_shift_3dict_nouns)

if (identical(stress_shift_3dict_using_bind, stress_shift_3dict)) {
  print("Celui avec les noms puis les verbes est identique.")
} else if (identical(stress_shift_3dict_using_reversed, stress_shift_3dict)) {
  print("Celui avec les verbes puis les noms est identique.")
} else {
  print("Aucun n'est identique au précédent : erreur !")
}
```
La fonction identical vérifie si les objets passés en arguments sont exactement identiques (cf, code chunk si dessous - vérification d'égalité numérique, et d'inégalité de strings). Ici, les deux tables ne valent pas la même chose pour cette fonction vu qu'il y a eu un changement d'ordre. Si la fonction vérifie ligne par ligne, par exemple, alors elle va bien dénoter la différence et renvoyer faux.

Si je devais utiliser ces données, cela importerait jusqu'à un certain point. En effet, il est essentiel de savoir quelles données on manipule si on ne veut pas faire d'erreur d'inattention. Pour éviter ce genre de problèmes il vaut mieux appeller précisément les données dont on a besoin (ergo, extraire les noms si on a besoin des noms, la même pour les verbes) et si on fusionne la table les contenant, alors soit cela doit indifférer, soit être capable de retrouver quelle donnée correspond à quoi.

```{r}
print(identical(1, 3 / 3))
print(identical("1", "3/3"))
```

#### Task D

```{r}
stress_shift_nouns <- dplyr::filter(stressshift::stress_shift_unamb, Category == "Noun")
stress_shift_nouns_selected <- dplyr::select(stress_shift_nouns, Word, Dict, Syllable)
stress_shift_nouns_renamed <- dplyr::rename(stress_shift_nouns_selected,
  Syllable_Noun = Syllable
)

stress_shift_verbs <- dplyr::filter(stressshift::stress_shift_unamb, Category == "Verb")
stress_shift_verbs_selected <- dplyr::select(stress_shift_verbs, Word, Dict, Syllable)
stress_shift_verbs_renamed <- dplyr::rename(stress_shift_verbs_selected,
  Syllable_Verb = Syllable
)

stress_shift_wide <- dplyr::inner_join(stress_shift_nouns_renamed, stress_shift_verbs_renamed)
```

Inner_join fusionne les deux tables passées en arguments en une seule par les noms de colonnes. Nos deux tables avaient donc les colonnes Word et Dict en commun (la console indique d'ailleurs "Joining, by = c("Word", "Dict")"). On n'a plus la catégorie vu que c'est ce par quoi on a sélectionné - on a donc l'instersection de ces deux dictionnaires.

###Task E

```{r}
p <- ggplot2::ggplot(
  stressshift::stress_shift_unamb,
  ggplot2::aes(x = Category, fill = Syllable)
) + ggplot2::geom_bar(colour = "black")
p <- p + ggplot2::scale_fill_brewer(palette = "Dark2")
print(p)
```

####Task F

```{r}
data_regroup <- dplyr::group_by(stress_shift_wide, Word)

stress_shift_byword <- dplyr::summarise(data_regroup,
  Noun_Percent_Syll_1 = (sum(Syllable_Noun == "Syllable 1") / n()) * 100,
  Verb_Percent_Syll_1 = (sum(Syllable_Verb == "Syllable 1") / n()) * 100
)

print(stress_shift_byword)
print(nrow(stress_shift_byword))
```

####Task G

```{r}
p <- ggplot2::ggplot(stress_shift_byword, ggplot2::aes(x = Noun_Percent_Syll_1, y = Verb_Percent_Syll_1))
p <- p + ggplot2::geom_point()
print(p)
```

####Task h

```{r}
stress_shift_wide_all <- dplyr::left_join(stress_shift_nouns_renamed, stress_shift_verbs_renamed)


data_regroup_all <- dplyr::group_by(stress_shift_wide_all, Word)

stress_shift_byword_all <- dplyr::summarise(data_regroup_all,
  Noun_Percent_Syll_1 = (sum(Syllable_Noun == "Syllable 1") / n()) * 100,
  Verb_Percent_Syll_1 = (sum(Syllable_Verb == "Syllable 1") / n()) * 100
)
```

#Exercice 3

```{r}

if (!exists(".Random.seed")) set.seed(NULL)
previous_seed <- .Random.seed
set.seed(12)
a <- data.frame("group" = "A", "value" = rnorm(50, 3, 2))
b <- data.frame("group" = "B", "value" = rnorm(50, 4, 2))
data <- dplyr::bind_rows(a, b)
set.seed(NULL)

t.test(a$value, b$value)
```
Le test essaie de déterminer dans quelle mesure les deux échantillons proviennent d'un ensemble. Il propose, entre autre, la moyenne de chacun : on veut donc savoir le rapport à l'hypothèse nulle, si les moyennes sont équivalents, ou tout du moins très proches, en fonction d'un risque donné. On a ici une p-value très basse (5.974e-05).
```{r}
if (!exists(".Random.seed")) set.seed(NULL)
previous_seed <- .Random.seed
set.seed(12)
a <- data.frame("group" = "A", "value" = rnorm(5, 3, 2))
b <- data.frame("group" = "B", "value" = rnorm(5, 4, 2))
data <- dplyr::bind_rows(a, b)
set.seed(NULL)

t.test(a$value, b$value)
```
L'intervalle de confiance, c'est-à-dire l'intervalle dans lequel la valeur estimée se retrouvera 95 fois sur 100 est pour ce jeu de données beaucoup plus grand que pour le précédent. Le fait d'avoir 10 fois moins de valeur rend l'estimation de la moyenne moins fiable car beaucoup plus dépendante de l'aléa du tirage (et de par exemple la présence d'outlyer) - contrairement à l'estimation précédente.
La p value est ici supérieure au seuil de significativité (0.05%), on peut donc accepter l'hypothèse null contrairement aux données précédentes.
#Exercice 4

```{r}
set.seed(12)
a_un <- data.frame("group" = "A", "value" = rnorm(5, 3, 2))
b_un <- data.frame("group" = "B", "value" = rnorm(5, 4, 2))
data_un <- dplyr::bind_rows(a_un, b_un)

a_deux <- data.frame("group" = "A", "value" = rnorm(50, 3, 2))
b_deux <- data.frame("group" = "B", "value" = rnorm(50, 4, 2))
data_deux <- dplyr::bind_rows(a_deux, b_deux)


a_trois <- data.frame("group" = "A", "value" = rnorm(5, 3, 6))
b_trois <- data.frame("group" = "B", "value" = rnorm(5, 4, 6))
data_trois <- dplyr::bind_rows(a_trois, b_trois)

a_quatre <- data.frame("group" = "A", "value" = rnorm(50, 3, 6))
b_quatre <- data.frame("group" = "B", "value" = rnorm(50, 4, 6))
data_quatre <- dplyr::bind_rows(a_quatre, b_quatre)

a_cinq <- data.frame("group" = "A", "value" = rnorm(5, 3, 2))
b_cinq <- data.frame("group" = "B", "value" = rnorm(5, 5, 2))
data_cinq <- dplyr::bind_rows(a_cinq, b_cinq)

a_six <- data.frame("group" = "A", "value" = rnorm(50, 3, 2))
b_six <- data.frame("group" = "B", "value" = rnorm(50, 5, 2))
data_six <- dplyr::bind_rows(a_six, b_six)

a_sept <- data.frame("group" = "A", "value" = rnorm(5, 3, 6))
b_sept <- data.frame("group" = "B", "value" = rnorm(5, 5, 6))
data_sept <- dplyr::bind_rows(a_sept, b_sept)

a_huit <- data.frame("group" = "A", "value" = rnorm(50, 3, 6))
b_huit <- data.frame("group" = "B", "value" = rnorm(50, 5, 6))
data_huit <- dplyr::bind_rows(a_huit, b_huit)

set.seed(NULL)
```



